<!doctype html>
<html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width, initial-scale=1.0"><meta name=description content="Gaël Varoquaux, computer / data / brain science"><link rel=alternate href=http://gael-varoquaux.info/feeds/all.atom.xml type=application/atom+xml title="Gaël Varoquaux Full Atom Feed"><title>Update on scikit-learn: recent developments for machine learning in Python -- Gaël Varoquaux: computer / data / brain science</title><link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/pure/0.3.0/pure-min.css><link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.2.0/css/font-awesome.min.css><link rel=stylesheet href=../theme/css/pure.css><script src=//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js></script></head><body><div class=pure-g-r id=layout><div class="sidebar sidebar-article pure-u"><header class=header-article><hgroup><a href=..><img class=avatar alt="Gaël Varoquaux" src=http://gael-varoquaux.info/images/gael.png></a><a href=.. class=article-info><h2 class=article-info>Gaël Varoquaux</h2></a><p>Wed 09 May 2012</p><a href=/>&larr;Home</a></hgroup></header></div><div class=pure-u><div class=content><section class=post><header class=post-header><h1>Update on scikit-learn: recent developments for machine learning in Python</h1><p class=post-meta> under <a class=post-category href=../tag/machine-learning.html>machine learning</a><a class=post-category href=../tag/python.html>python</a><a class=post-category href=../tag/science.html>science</a><a class=post-category href=../tag/scikit-learn.html>scikit-learn</a><a class=post-category href=../tag/sprint.html>sprint</a><span class=social_links><a href=http://twitter.com/share class=twitter-share-button data-count=horizontal data-via=GaelVaroquaux>Tweet</a><script type=text/javascript src=http://platform.twitter.com/widgets.js async defer></script><span class=g-plusone data-size=medium></span></span></p></header></section><p>Yesterday, we released version 0.11 of the <a class="reference external" href=http://scikit-learn>scikit-learn</a> toolkit for machine learning in Python, and there was much rejoincing.</p><div class=section id=major-features-gained-in-the-last-releases><h2>Major features gained in the last releases</h2><p>In the last 6 months, there have been many things happening with the scikit-learn. While I do not whish to give an exhaustive summary of features added (it can be found <a class="reference external" href=http://scikit-learn.org/stable/whats_new.html>here</a>), let me list a few of the additions that I personnally find exciting.</p><div class=section id=non-linear-prediction-models><h3>Non-linear prediction models</h3><p>For complex prediction problems where there is no simple model available, as in computer vision, non-linear models are handy. A good example of such models are those based on decisions trees and model averaging. For instance random forests are used in the Kinect to locate body parts. As they are intrinsically complex, they may need a large amount of training data. For this reason, they have been implemented in the scikit-learn with special attention to computational efficiency.</p><ul class=simple><li><a class="reference external" href=http://scikit-learn.org/stable/modules/ensemble.html#forests-of-randomized-trees>Randomized Forests and extra-trees</a></li><li><a class="reference external" href=http://scikit-learn.org/stable/modules/ensemble.html#gradient-tree-boosting>Gradient boosted regression trees</a></li></ul></div><div class=section id=dealing-with-unlabeled-instances><h3>Dealing with unlabeled instances</h3><p>It is often easy to gather unlabeled observations than labeled observation. While prediction of a quantity of interest is then harder or simply impossible, mining this data can be useful.</p><p><a class="reference external" href=http://scikit-learn.org/stable/modules/label_propagation.html>Semi-supervised learning</a>: using unlabeled observations together with labeled ones for better prediction.</p><hr class=docutils><p><a class="reference external" href=http://scikit-learn.org/stable/modules/outlier_detection.html>Outlier/novelty detection</a>: detect deviant observations.</p><hr class=docutils><p><a class="reference external" href=http://scikit-learn.org/stable/modules/manifold.html>Manifold learning</a>: discover a non-linear low-dimensional structure in the data.</p><hr class=docutils><p><a class="reference external" href=http://scikit-learn.org/stable/modules/clustering.html>Clustering</a> with <a class="reference external" href=http://scikit-learn.org/stable/modules/clustering.html#mini-batch-k-means>an algorithm</a> that can scale to really large datasets using an online approach: fitting small portions of the data on after the other (Mini-batch k-means).</p><hr class=docutils><p><a class="reference external" href=http://scikit-learn.org/stable/modules/decomposition.html#dictionarylearning>Dictionary learning</a>: learning patterns in the data that represent it sparsely: each observation is a combination of a small number patterns.</p></div><div class=section id=sparse-models-when-very-few-descriptors-are-relevant><h3>Sparse models: when very few descriptors are relevant</h3><p>In general, finding which descriptors are useful when there are many of them is like find a needle in a haystack: it is a very hard problem. However, you know that only a few of these descriptors actually carry information, you are in a so-called <em>sparse</em> problem, for specific approaches can work well.</p><p><a class="reference external" href=http://scikit-learn.org/stable/modules/linear_model.html#orthogonal-matching-pursuit-omp>Orthogonal matching pursuit</a>: a greedy and fast algorithm for very sparse linear models</p><hr class=docutils><p><a class="reference external" href=http://scikit-learn.org/stable/modules/feature_selection.html#randomized-sparse-models>Randomized sparsity (randomized Lasso)</a>: selecting the relevant descriptors in noisy high-dimensional observations</p><hr class=docutils><p><a class="reference external" href=http://scikit-learn.org/stable/modules/generated/sklearn.covariance.GraphLasso.html#sklearn.covariance.GraphLasso>Sparse inverse covariance</a>: learning graphs of connectivity from correlations in the data</p><div class=section id=getting-developpers-together-the-granada-sprint><h4>Getting developpers together: the Granada sprint</h4><p><object width=400 height=300 align=right><embed type=application/x-shockwave-flash src="http://www.flickr.com/apps/slideshow/show.swf?v=109615" allowfullscreen=true flashvars="offsite=true⟨=en-us&amp;page_show_url=%2Fsearch%2Fshow%2F%3Fq%3Dscikit-learn%26m%3Dtags%26w%3D66885349%2540N03&amp;page_show_back_url=%2Fsearch%2F%3Fq%3Dscikit-learn%26m%3Dtags%26w%3D66885349%2540N03&amp;method=flickr.photos.search&amp;api_params_str=&amp;api_tags=scikit-learn&amp;api_tag_mode=bool&amp;api_user_id=66885349%40N03&amp;api_safe_search=3&amp;api_content_type=7&amp;api_media=all&amp;api_sort=date-posted-desc&amp;jump_to=&amp;start_index=0" width=400 height=300></object></p><p>Of course, such developments happen only because we have a great team of <a class="reference external" href=https://github.com/scikit-learn/scikit-learn/graphs/contributors>dedicated coders</a>.</p><p>Getting along and working together is a critical part of the project. In December 2011, we held the first international <a class="reference external" href=http://scikit-learn>scikit-learn</a> sprint in Granada, on the side of the <a class="reference external" href=http://nips.cc>NIPS conference</a>. That was a while ago, and I haven’t found time to blog about it, maybe because I was too busy merging in the code produced :). Here is a small report from my point of view. Better late than never.</p></div></div></div><div class=section id=participants-from-all-over-the-globe><h2>Participants from all over the globe</h2><p>This sprint was a big deal for us, because for the first time, thanks to sponsor money, we were able to fly contributors from overseas and meet the team in person. For the first time I was able to see the faces behind many of the fantastic people that I knew only from the mailing list.</p><p>I really think that we must thank our sponsors, <strong>Google</strong> and <strong>tinyclues</strong>, but also The PSF, that is in particular Jesse Noller but especially <strong>Steve Holden</strong>, whose help was absolutely instrumental in getting sponsor money. This money is what made it possible to unite a good fraction of the team, and it opened the door to great moments of coding, and more.</p></div><div class=section id=producing-code-lines-and-friendship><h2>Producing code lines and friendship</h2><p>An important aspect of the sprint for me was that I really felt the team being united. Granada is a great city and we spent fantastic moments together. Now when I review code, I can often put a face on the author of that code and remember a walk below the Alhambra or an evening in a bar. I am sure it helps reviewing code!</p></div><div class=section id=was-it-worth-the-money><h2>Was it worth the money?</h2><img alt src=http://gael-varoquaux.info/blog/wp-content/uploads/2012/skl_activity.png style="width: 90%;"><p>I really appreciate that the sponsors did not ask for specific returns on investment beyond acknowledgments, but I think that it is useful for us to ask the question: was it worth the money? After all, we got around $5000, and that’s a lot of money. First of all, as a side effect of the sprint, people who had invested a huge amount of time in a machine learning toolkit without asking anything in return got help to go to a major machine learning conference.</p><p>But was there a return over investment in terms of code? If you look at the number of lines of code modified weekly (figure on the right), there is a big spike in December 2011. That’s our sprint! Importantly, if you look at the months following the sprint, there still is a lot of activity in the months following the sprint. This is actually unusual, as the active developments happen more in the summer break than during the winter, as our developpers are busy working on papers or teaching.</p><p>The explaination is simple: we where thrilled by the sprint. Overall, it was incredibly beneficial to the project. I am looking forward to the next ones.</p></div><div class=hr style="margin-bottom: -.5em;"></div><span class=social_links><a href=http://twitter.com/share class=twitter-share-button data-count=horizontal data-via=GaelVaroquaux>Tweet</a><script type=text/javascript src=http://platform.twitter.com/widgets.js async defer></script><span class=g-plusone data-size=medium></span></span><a href=# class=go-top>Go Top</a><div class=comments><div id=disqus_thread></div><script type=text/javascript>
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = "gaelvaroquaux"; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script><noscript>Please enable JavaScript to view the <a href=http://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=http://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><footer class=footer><p>&copy; Gaël Varoquaux &ndash; Built with <a href=https://github.com/PurePelicanTheme/pure>Pure Theme</a> for <a href=http://blog.getpelican.com/>Pelican</a></p></footer></div></div></div><script src=//cdnjs.cloudflare.com/ajax/libs/fitvids/1.0.1/jquery.fitvids.min.js></script><script>
        $(document).ready(function(){
            $(".content").fitVids();
        });
    </script><script>
        var $top = $('.go-top');

        // Show or hide the sticky footer button
        $(window).scroll(function() {
            if ($(this).scrollTop() > 200) {
                $top.fadeIn(200);
            } else {
                $top.fadeOut(200);
            }
        });

        // Animate the scroll to top
        $top.click(function(event) {
            event.preventDefault();
            $('html, body').animate({scrollTop: 0}, 300);
        })

        // Makes sure that the href="#" attached to the <a> elements
        // don't scroll you back up the page.
        $('body').on('click', 'a[href="#"]', function(event) {
            event.preventDefault();
        });
    </script><script src=https://apis.google.com/js/platform.js async defer></script><script type=text/javascript>
        var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
        document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
    </script><script type=text/javascript>
        try {
            var pageTracker = _gat._getTracker("UA-55589822-1");
            pageTracker._trackPageview();
            } catch(err) {}
    </script></body></html>