<!doctype html>
<html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width, initial-scale=1.0"><meta name=description content="Gaël Varoquaux, computer / data / brain science"><link rel=alternate href=http://gael-varoquaux.info/feeds/all.atom.xml type=application/atom+xml title="Gaël Varoquaux Full Atom Feed"><title>Nilearn sprint: hacking neuroimaging machine learning -- Gaël Varoquaux: computer / data / brain science</title><link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/pure/0.3.0/pure-min.css><link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.2.0/css/font-awesome.min.css><link rel=stylesheet href=../theme/css/pure.css><script src=//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js></script></head><body><div class=pure-g-r id=layout><div class="sidebar sidebar-article pure-u"><header class=header-article><hgroup><a href=..><img class=avatar alt="Gaël Varoquaux" src=http://gael-varoquaux.info/images/gael.png></a><a href=.. class=article-info><h2 class=article-info>Gaël Varoquaux</h2></a><p>Tue 04 August 2015</p><a href=/>&larr;Home</a></hgroup></header></div><div class=pure-u><div class=content><section class=post><header class=post-header><h1>Nilearn sprint: hacking neuroimaging machine learning</h1><p class=post-meta> under <a class=post-category href=../tag/neuroimaging.html>neuroimaging</a><a class=post-category href=../tag/python.html>python</a><a class=post-category href=../tag/scientific-computing.html>scientific computing</a><a class=post-category href=../tag/scipy.html>scipy</a><span class=social_links><a href=http://twitter.com/share class=twitter-share-button data-count=horizontal data-via=GaelVaroquaux>Tweet</a><script type=text/javascript src=http://platform.twitter.com/widgets.js async defer></script><span class=g-plusone data-size=medium></span></span></p></header></section><p>A couple of weeks ago, we had in Paris the second international <a class="reference external" href=http://nilearn.github.io>nilearn</a> sprint, dedicated to making <strong>machine learning in neuroimaging easier and more powerful</strong>.</p><p>It was such a fantastic experience, as nilearn is really shaping up as a simple yet powerful tool, and there is a lot of enthusiasm. For me, this sprint is a turning point, as I could see people other than the original core team (that spanned out of <a class="reference external" href=https://team.inria.fr/parietal/>our research team</a>) excited about the project’s future. Thank you to all who came:</p><ul class="columns simple"><li>Ahmed Kanaan</li><li>Andres Hoyos Idrobo</li><li>Alexandre Abraham</li><li>Arthur Mensch</li><li>Ben Cipolli (remote)</li><li>Bertrand Thirion</li><li>Chris Filo Gorgolewski</li><li>Danilo Bzdok</li><li>Elvis Dohmatob</li><li>Julia Hutenburg</li><li>Kamalaker Dadi</li><li>Loic Esteve</li><li>Martin Perez</li><li>Michael Hanke</li><li>Oscar Nájera, working on <a class="reference external" href=http://sphinx-gallery.readthedocs.org/>sphinx-gallery</a></li></ul><img alt src=attachments/nilearn_july_2015_sprint/nilearn_sprint.jpg style="width: 100%;"><p>The sprint was a joint sprint with the <a class="reference external" href=http://martinos.org/mne/stable/mne-python.html>MNE-Python</a> team, that makes MEG processing awesome. We also need to thank <a class="reference external" href=http://alexandre.gramfort.net>Alex Gramfort</a>, who did most of the work to set up the sprint, as well as <a class="reference external" href=https://www.universite-paris-saclay.fr/en/research/project/lidex-neurosaclay>NeuroSaclay</a> for funding, and <a class="reference external" href=http://lapaillasse.org/>La paillasse</a>, <a class="reference external" href=http://www.telecom-paristech.fr>Telecom</a>, and <a class="reference external" href=http://www.inria.fr/en/centre/saclay>INRIA</a> for hosting.</p><div class=section id=highlights-of-the-sprints-results><h2>Highlights of the sprints results</h2><p><strong>Plotting of multiple maps</strong></p><blockquote><a class="reference external image-reference" href=https://circle-artifacts.com/gh/nilearn/nilearn/128/artifacts/0/home/ubuntu/nilearn/doc/_build/html/auto_examples/connectivity/plot_canica_resting_state.html><img alt class=align-right src=attachments/nilearn_july_2015_sprint/plot_canica_resting_state_001.png style="width: 200px;"></a><p>A function to visualize overlays of various maps, eg for a probabilistic atlas, with defaults that try to adapt to the number of maps (see the <a class="reference external" href=https://circle-artifacts.com/gh/nilearn/nilearn/128/artifacts/0/home/ubuntu/nilearn/doc/_build/html/auto_examples/manipulating_visualizing/plot_prob_atlas.html>example</a>). It’s very useful for example for <a class="reference external" href=https://circle-artifacts.com/gh/nilearn/nilearn/128/artifacts/0/home/ubuntu/nilearn/doc/_build/html/auto_examples/connectivity/plot_canica_resting_state.html>easy visualizing of ICA components</a>.</p></blockquote><p><strong>Sign of activation in glass brain</strong></p><blockquote><a class="reference external image-reference" href=https://circle-artifacts.com/gh/nilearn/nilearn/287/artifacts/0/home/ubuntu/nilearn/doc/_build/html/auto_examples/manipulating_visualizing/plot_demo_glass_brain_extensive.html><img alt class=align-right src=attachments/nilearn_july_2015_sprint/plot_demo_glass_brain_extensive_005.png style="width: 200px;"></a><p>Our glass brain plotting was greatly improved adding amongst other things the option to capture the sign of the activation in the color (see this <a class="reference external" href=https://circle-artifacts.com/gh/nilearn/nilearn/287/artifacts/0/home/ubuntu/nilearn/doc/_build/html/auto_examples/manipulating_visualizing/plot_demo_glass_brain_extensive.html>example</a>).</p></blockquote><p><strong>Spatially-regularized decoder</strong></p><blockquote><a class="reference external image-reference" href=https://circle-artifacts.com/gh/nilearn/nilearn/287/artifacts/0/home/ubuntu/nilearn/doc/_build/html/auto_examples/decoding/plot_haxby_space_net.html><img alt class=align-right src=attachments/nilearn_july_2015_sprint/plot_haxby_space_net_002.png style="width: 200px;"></a><p>Decoders based on GraphNet and total variation have finally landed in nilearn. This has required a lot of work to get fast convergence and robust parameter selection. At the end of the day, it is much slower than an SVM, but the maps look splendid (see this <a class="reference external" href=https://circle-artifacts.com/gh/nilearn/nilearn/287/artifacts/0/home/ubuntu/nilearn/doc/_build/html/auto_examples/decoding/plot_haxby_space_net.html>example</a>).</p></blockquote><p><strong>Sparse dictionary learning</strong></p><blockquote><a class="reference external image-reference" href=https://circle-artifacts.com/gh/nilearn/nilearn/282/artifacts/0/home/ubuntu/nilearn/doc/_build/html/auto_examples/connectivity/plot_dict_learning_resting_state.html><img alt class=align-right src=attachments/nilearn_july_2015_sprint/plot_dict_learning_resting_state_001.png style="width: 200px;"></a><p>We have almost merged sparse dictionnary learning as a alternative to ICA. Experience shows that on resting-state data, it gives more contrasted segmentation of networks (see this <a class="reference external" href=https://circle-artifacts.com/gh/nilearn/nilearn/282/artifacts/0/home/ubuntu/nilearn/doc/_build/html/auto_examples/connectivity/plot_dict_learning_resting_state.html>example</a>).</p></blockquote><p><strong>New installation docs</strong></p><blockquote> New webpage layout using tabs to display only the installation instruction relevant to the OS of the user (see <a class="reference external" href=https://circle-artifacts.com/gh/nilearn/nilearn/287/artifacts/0/home/ubuntu/nilearn/doc/_build/html/introduction.html#installation>here</a>). The results are more compact and more clear instructions, that I hope will make our users’ life easier.</blockquote><p><strong>CircleCI integration</strong></p><blockquote> We now use <a class="reference external" href=https://circleci.com/gh/nilearn/nilearn>CircleCI</a> to run the examples and build the docs. This is challenging because our examples are real cases of neuroimaging data analysis, and thus require heavy datasets and computing horse power.</blockquote><p><strong>Neurodebian packaging</strong></p><blockquote> There are now <a class="reference external" href=http://neuro.debian.net/pkgs/python-nilearn.html>neurodebian packages</a> for nilearn.</blockquote><p>And much more!</p><div class=warning><p class="first admonition-title">Warning</p><p class=last>Features listed above are <strong>not</strong> in the released version of nilearn. You need to wait a month or so.</p></div></div><div class=hr style="margin-bottom: -.5em;"></div><span class=social_links><a href=http://twitter.com/share class=twitter-share-button data-count=horizontal data-via=GaelVaroquaux>Tweet</a><script type=text/javascript src=http://platform.twitter.com/widgets.js async defer></script><span class=g-plusone data-size=medium></span></span><a href=# class=go-top>Go Top</a><div class=comments><div id=disqus_thread></div><script type=text/javascript>
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = "gaelvaroquaux"; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script><noscript>Please enable JavaScript to view the <a href=http://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=http://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><footer class=footer><p>&copy; Gaël Varoquaux &ndash; Built with <a href=https://github.com/PurePelicanTheme/pure>Pure Theme</a> for <a href=http://blog.getpelican.com/>Pelican</a></p></footer></div></div></div><script src=//cdnjs.cloudflare.com/ajax/libs/fitvids/1.0.1/jquery.fitvids.min.js></script><script>
        $(document).ready(function(){
            $(".content").fitVids();
        });
    </script><script>
        var $top = $('.go-top');

        // Show or hide the sticky footer button
        $(window).scroll(function() {
            if ($(this).scrollTop() > 200) {
                $top.fadeIn(200);
            } else {
                $top.fadeOut(200);
            }
        });

        // Animate the scroll to top
        $top.click(function(event) {
            event.preventDefault();
            $('html, body').animate({scrollTop: 0}, 300);
        })

        // Makes sure that the href="#" attached to the <a> elements
        // don't scroll you back up the page.
        $('body').on('click', 'a[href="#"]', function(event) {
            event.preventDefault();
        });
    </script><script src=https://apis.google.com/js/platform.js async defer></script><script type=text/javascript>
        var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
        document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
    </script><script type=text/javascript>
        try {
            var pageTracker = _gat._getTracker("UA-55589822-1");
            pageTracker._trackPageview();
            } catch(err) {}
    </script></body></html>