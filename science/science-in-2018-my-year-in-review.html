<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width, initial-scale=1.0"><meta name=description content="Gaël Varoquaux, computer / data / brain science"><link rel=alternate href=http://gael-varoquaux.info/feeds/all.atom.xml type=application/atom+xml title="Gaël Varoquaux Full Atom Feed"><title>Science in 2018: my year in review -- Gaël Varoquaux: computer / data / brain science</title><link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/pure/0.3.0/pure-min.css><link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.2.0/css/font-awesome.min.css><link rel=stylesheet href=../theme/css/pure.css><script src=//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js></script></head><body><div class=pure-g-r id=layout><div class="sidebar sidebar-article pure-u"><header class=header-article><hgroup><a href=..><img class=avatar alt="Gaël Varoquaux" src=http://gael-varoquaux.info/images/gael.png></a><a href=.. class=article-info><h2 class=article-info>Gaël Varoquaux</h2></a><p>Thu 03 January 2019</p><a href=/ >&larr;Home</a></hgroup></header></div><div class=pure-u><div class=content><section class=post><header class=post-header><h1>Science in 2018: my year in review</h1><p class=post-meta> under <a class=post-category href=../tag/science.html>science</a><a class=post-category href=../tag/research.html>research</a><a class=post-category href=../tag/machine-learning.html>machine learning</a><a class=post-category href=../tag/neuroimaging.html>neuroimaging</a><a class=post-category href=../tag/brain-science.html>brain science</a><span class=social_links><a href=http://twitter.com/share class=twitter-share-button data-count=horizontal data-via=GaelVaroquaux>Tweet</a><script type=text/javascript src=http://platform.twitter.com/widgets.js async defer></script><span class=g-plusone data-size=medium></span></span></p></header></section><p>From a scientific perspective, 2018 <a class=footnote-reference href=#id2 id=id1>[1]</a> was once again extremely exciting thank to awesome collaborators (at <a href=https://team.inria.fr/parietal/ class="reference external">Inria</a>, with <a href=https://project.inria.fr/dirtydata/ class="reference external">DirtyData</a>, and our <a href=https://scikit-learn.fondation-inria.fr/ class="reference external">local scikit-learn team</a>). Rather than going over everything that we did in 2018, I would like to give a few highlights: We published major work using <strong>machine learning to map cognition in the brain</strong>, We started a new research project on <strong>analysis of non-curated data</strong> (addressing all of data science, beyond brain imaging); And we worked a lot on <strong>growing scikit-learn</strong>.</p><table class="side-hanging docutils footnote" frame=void id=id2 rules=none><colgroup><col class=label><col></colgroup><tbody valign=top><tr><td class=label><a class=fn-backref href=#id1>[1]</a></td><td>It’s already 2019, I am indeed late in posting this summary.</td></tr></tbody></table><div class="contents topic" id=highlights><p class="topic-title first">Highlights</p><ul class=simple><li><a class="reference internal" href=#cognitive-brain-mapping id=id5>Cognitive brain mapping</a></li><li><a class="reference internal" href=#data-science-without-data-cleaning id=id6>Data science without data cleaning</a></li><li><a class="reference internal" href=#scikit-learn-growth-and-consolidation id=id7>Scikit-learn: growth and consolidation</a></li></ul></div><div class=line-block><div class=line><br></div></div><div class=section id=cognitive-brain-mapping><h2><a class=toc-backref href=#id5>Cognitive brain mapping</a></h2><p>We have been exploring <strong>how predictive models can help mapping cognition in the human brain</strong>. In 2018, these long-running efforts led to important publications.</p><div class=line-block><div class=line><br></div></div><div class=section id=atlases-of-cognition-with-large-scale-human-brain-mapping><h3>Atlases of cognition with large-scale human brain mapping</h3><p>More than 6 years ago, with my student Yannick Schwartz, we started working on <strong>compiling an altases of cognition across many cognitive neuroimaging studies</strong>. This turned out to be quite challenging for several reasons:</p><ul class=simple><li><strong>Formalizing the links between mental processes</strong> studied across the literature is challenging. Strictly speaking, every paper studies a different mental process. However, to build an atlas of cognition, we are interested in finding commonalities across the literature.</li><li>While cognitive studies tend to target a specific mental function, the psychological manipulations that they use also recruit many other processes. For instance, a memory study might use a <em>visual n-back</em> task, and hence recruit the visual cortex. The problem is more than an experimental inconvience: <strong>varying details of an experiment may trigger different cognitive processes</strong>. For instance, there are common and separate pathways for visual word recognition and auditory word recognition.</li><li>Simply <strong>detecting regions that are recruited in a given mental operation leads to selecting the whole cortex</strong> with enough statistical power. Indeed tasks are never fully balanced; reading might for instance require more attention than listening.</li></ul><p>These challenges are related on the one hand to the problem of <a class="reference external" href=https://www.sciencedirect.com/science/article/pii/S1364661305003360>reverse inference</a><a class=footnote-reference href=#id4 id=id3>[2]</a>, and on the other hand to that of mental-process decomposition, or cognitive subtraction, both central to cognitive neuroimaging. They also call for formal knowledge representation, <em>eg</em> by building ontologies, which is a task harder than it might seem at first glance.</p><table class="side-hanging docutils footnote" frame=void id=id4 rules=none><colgroup><col class=label><col></colgroup><tbody valign=top><tr><td class=label><a class=fn-backref href=#id3>[2]</a></td><td>In essence, the reverse inference problem arises because in a cognitive brain imaging the observed brain activity is a consequence of the behavior, and not a cause. While a conclusion that activity in a brain structure causes a certain behavior is desirable, it is not directly supported by a cognition neuroimaging experiment.</td></tr></tbody></table><p>In our work <a class="reference external" href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006565">[Varoquaux et al, PLOS 2018]</a>, we tackled these challenges to build atlases of cognition as follows:</p><ul class=simple><li>We assigned to each brain-activity image labels describing the <em>multiple</em> mental processes related to the experimental manipulation</li><li>We used decoding –<em>ie</em> prediction of the cognitive labels from the brain activity– to ground a principled <em>reverse inference</em> interpretation: regions selected indeed do imply the corresponding behavior.</li><li>Regions in the atlas were built of brain structures that both implied the corresponding cognition, and were triggered by it (conditional and marginal link), to ground a strong selectivity:</li></ul><div class="figure align-center"><a class="reference external image-reference" href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006565"><img alt src=attachments/2018_highlights/mapping_types.png style="width: 700px;"></a></div><p>We applied these techniques to the data from 30 different studies, resulting in a detailed break down of the cortex in functionally-specialized modules:</p><div class="figure align-center"><a class="reference external image-reference" href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006565"><img alt src=attachments/2018_highlights/cognitive_regions.png style="width: 700px;"></a></div><p>Importantly, the validity of this decomposition in regions is established by the ability of these regions to predict the cognitive aspects of new experimental paradigms.</p><div class=line-block><div class=line><br></div></div></div><div class=section id=predictive-models-avoid-excessive-reductionism-in-cognitive-neuroimaging><h3>Predictive models avoid excessive reductionism in cognitive neuroimaging</h3><div class="figure align-right"><img alt src=attachments/2018_highlights/decoding.png style="width: 400px;"></div><p>While machine learning is generally seen as an engineering tool to build predictive models or automate tasks, I see in it a central method of modern science. Indeed, it can distill <strong>evidence that generalizes</strong> from vast –high dimensional– and ill-structured experimental data. Beyond prediction, it can guide understanding.</p><p>With Russ Poldrack, we wrote an opinion paper <a href=https://hal.archives-ouvertes.fr/hal-01856412/ class="reference external">[Varoquaux &amp; Poldrack, Curr Opinion Neurobio 2019]</a> that details why predictive models are important tools to building wider theories of brain function. It reviews many exciting progresses in uncovering with predictive models how brain mechanisms support the mind. It makes the point that <strong>ability generalize is a fundamentally desirable priority of scientific inference</strong>. Models that are grounded on explicit generalization give a solid path to build broad theories of the mind. Particularly interesting is generalization to significantly different settings, <em>ie</em> going further than typical cross-validation experiments of machine learning, where identical data are artificially split.</p><p>Something that is dear to my heart is that we are aiming for <strong>quantitative generalization</strong>, while psychology often contents itself with qualitative generalization.</p><div class=line-block><div class=line><br></div></div></div><div class=section id=individual-brain-charting-a-high-resolution-fmri-dataset-for-cognitive-mapping><h3>Individual Brain Charting, a high-resolution fMRI dataset for cognitive mapping</h3><p>We are convinced about the importance of analyzing brain response across multiple paradigms, to build models of brain function that generalize across these paradigms. However, addressing such a research program by aggregating multiple studies is hindered by data heterogeneity, due to inter-individual differences or to differing scanners.</p><p>Hence, my team, <a href=https://team.inria.fr/parietal/ class="reference external">Parietal</a>, has undertook a major data acquisition, the <a class="reference external" href=https://project.inria.fr/IBC>Individual Brain Charting project</a>: scanning a few individuals under a huge amount of cognitive tasks. The data acquisition will last for many years, as the individuals come back to the lab for new acquisitions. The images are of excellent quality, thanks to the unique expertise of our scanning site, Neurospin, a brain-imaging research facility.</p><p>The data are completely <strong>openly accessible</strong>: the raw data, preprocessed data, statistical outputs, alongside with the processing script. We are releasing new data as the project moves forward. This year, we published the data paper <a class="reference external" href=https://www.nature.com/articles/sdata2018105>[Pinho et al, Scientific Data 2018]</a>.</p><div class=line-block><div class=line><br></div></div><div class=topic><p class="topic-title first">Data accumulation in brain imaging</p><p>We are living exciting times, as <strong>there are more and more large volumes of shared brain imaging data</strong>. <a href=https://openfmri.org/ class="reference external">OpenfMRI</a> aggregates data in a consistent way across brain-imaging studies. Large projects such as the Human Connectome Project, our Individual Brain Charting project, or the UK BioBank, are designed from the beginning to be shared. We are entering an era of brain-image analysis on many terabytes of data, with dozens of thousands of subjects, compounding hundreds of different clinical or cognitive conditions.</p><p>Massive data accumulation opens exciting new scientific prospects, and raises new engineering challenges. Some of these challenges are to scale up neuroimaging data-processing practices, eg inter-subject alignments at the scale of many thousands subjects. Some of these challenges are new to neuroimaging: <strong>when compounding hundreds of sources of data into an analysis, the human cost of data integration becomes a major roadblock</strong>. As I have become convinced that analysing more, and more diverse, data is an important way forward, I have started working on data intergration per se.</p></div><div class=line-block><div class=line><br></div><div class=line><br></div></div></div></div><div class=section id=data-science-without-data-cleaning><h2><a class=toc-backref href=#id6>Data science without data cleaning</a></h2><div class=section id=a-new-personal-research-agenda-dirtydata><h3>A new personal research agenda: DirtyData</h3><p>Challenges to integrating data in a statistical analysis are ubiquitous, including in brain imaging. Data cleaning <a class="reference external" href=https://www.kaggle.com/surveys/2017>is recognized</a> as the number one time sink for data scientists. When advising scikit-learn users, including very large companies, I often find that the major roadblock is going from the raw data sources to the data matrix that is input to scikit-learn.</p><p>A year ago, I started a new research focus, around the <a class="reference external" href=https://project.inria.fr/dirtydata>DirtyData project</a>. We now have a team with multiple exciting collaborations, and funding. Our goal is to <strong>facilitate statistical analysis of non-curated data</strong>. We hope to foster better understanding of how powerful machine-learning models can cope with imperfect, non homogeneous data. As we go, we will publish this understanding, but also distribute code with new methods, and hopefully influence common data-science practices and software. This is an exciting adventure (and yes, <strong>we are hiring</strong>; see our <a class="reference external" href=https://project.inria.fr/dirtydata/job-offers>job offers</a> or contact me).</p><p>The topics are vast, at the intersection between database research and statistics. In particular, it calls for integrating machine learning with:</p><ul class=simple><li>Knowledge representation</li><li>Information retrieval</li><li>Information extraction</li><li>Statistics with missing data</li></ul><div class=line-block><div class=line><br></div></div></div><div class=section id=similarity-encoding-analysis-with-non-normalized-string-categories><h3>Similarity encoding: analysis with non-normalized string categories</h3><p>While the DirtyData project is young, we already made progress for analysis of <strong>dirty categories, ie categorical data represented with strings that lack curation</strong>. These can have typos or other simple morphological variants (<em>eg</em> “patient” vs “patients”), or they can have more structured and fundamental differences, <em>eg</em> arising from the merge of multiple data sources. This latter problem is well-known of database research, where it is seen as a <em>record linkage</em> or <em>alignment</em> problem.</p><p>For statistical analysis, in particular machine learning, the problem with these non-curated string categories is that they must be encoded to numerical representations, and classic categorical encodings are not well suited for them. For instance, one-hot encoding leads to very high cardinality.</p><p>In <a class="reference external" href=https://hal.inria.fr/hal-01806175>Cerda et al (2018)</a>, we contribute a simple encoding approach, <em>similarity encoding</em>, based on interpolating one-hot encoding with string similarities between the categories.</p><div class="figure align-center"><a class="reference external image-reference" href=https://dirty-cat.github.io/stable/auto_examples/01_investigating_dirty_categories.html><img alt src=attachments/2018_highlights/investigating_dirty_categories.png style="width: 600px;"></a></div><div class="figure align-right"><a class="reference external image-reference" href=https://dirty-cat.github.io/stable/auto_examples/02_fit_predict_plot_employee_salaries.html><img alt src=attachments/2018_highlights/predict_employee_salaries.png style="width: 230px;"></a></div><p>We run an extensive empirical study, and show that <strong>similarity encoding leads to better prediction accuracy without curation of the data</strong>, outperforming all the other approaches that we tried. The paper is purely empirical, but stay tuned: a theoretical analysis of why this is the case is coming soon.</p><p>For the benefit of data scientists and researchers, we are released a small Python package, <a href=https://dirty-cat.github.io/stable/ class="reference external">dirty-cat</a>, for learning with dirty categories.</p><p>This is just the beginning of the DirtyData project, more exciting work is under way.</p><div class=line-block><div class=line><br></div></div></div></div><div class=section id=scikit-learn-growth-and-consolidation><h2><a class=toc-backref href=#id7>Scikit-learn: growth and consolidation</a></h2><img alt class=align-right src=attachments/2018_highlights/scikit-learn-logo-notext.png style="width: 150px;"><p>In 2018, a lot of my energy went to consolidating scikit-learn as a project. Describing the work in detail is for another post. However, my main efforts where around growing the team and working on sustainability.</p><ul class=simple><li>We established a <a href=https://scikit-learn.fondation-inria.fr/ class="reference external">scikit-learn foundation at Inria</a>, in which companies partner with us to fund scikit-learn development. This took a lot of effort to establish good partnerships and create the legal vessels. Indeed, we want to make sure that the common effort is invested to make scikit-learn better. For instance, working with Intel, who are somewhat running an arms race for computing speed, we improved our test suite, and are slowly but surely learning how to improve our speed.</li><li>A consequence of the foundation is that we are hiring to grow the team (check out <a href=https://scikit-learn.fondation-inria.fr/people/ class="reference external">our open positions</a>). In 2018, my own team grew, with more excellent people working on scikit-learn, but also <a href=http://joblib.readthedocs.io/ class="reference external">joblib</a>, and even contributing to core Python and numpy to improve <a class="reference external" href=https://github.com/python/cpython/pull/3895>parallel computing</a> and <a class="reference external" href=https://github.com/numpy/numpy/pull/12133>pickling</a>.</li><li>As the scikit-learn community is growing, it seemed important to formalize a bit more how decisions are made. To me, an important aspect was laying out clearly that the project is still governed by the community, and not partners or people paid by the foundation. We have a draft of a <a class="reference external" href=https://github.com/scikit-learn/scikit-learn/pull/12878>governance document</a>, that is pretty much ready for merge. We also worked on a <a class="reference external" href=https://scikit-learn.org/dev/roadmap.html>roadmap</a>. It is a non binding document, but it still was an interesting exercise.</li><li>Scikit-learn 0.20 was released, <a class="reference external" href=https://scikit-learn.org/dev/whats_new.html>with many enhancements</a>. And the 0.20 release was followed by two minor releases, to make sure that our users got robust code with backward compatibility.</li></ul><div class=line-block><div class=line><br></div></div><p>We are busy finishing a few very interesting studies; next year will be exciting! I hope that we will have much to say about population analysis with brain imaging, which is a amazingly interesting subject.</p></div><div class=hr style="margin-bottom: -.5em;"></div><span class=social_links><a href=http://twitter.com/share class=twitter-share-button data-count=horizontal data-via=GaelVaroquaux>Tweet</a><script type=text/javascript src=http://platform.twitter.com/widgets.js async defer></script><span class=g-plusone data-size=medium></span></span><a href=# class=go-top>Go Top</a><div class=comments><div id=disqus_thread></div><script type=text/javascript>
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = "gaelvaroquaux"; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script><noscript>Please enable JavaScript to view the <a href=http://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=http://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><footer class=footer><p>&copy; Gaël Varoquaux &ndash; Built with <a href=https://github.com/PurePelicanTheme/pure>Pure Theme</a> for <a href=http://blog.getpelican.com/ >Pelican</a></p></footer></div></div></div><script src=//cdnjs.cloudflare.com/ajax/libs/fitvids/1.0.1/jquery.fitvids.min.js></script><script>
        $(document).ready(function(){
            $(".content").fitVids();
        });
    </script><script>
        var $top = $('.go-top');

        // Show or hide the sticky footer button
        $(window).scroll(function() {
            if ($(this).scrollTop() > 200) {
                $top.fadeIn(200);
            } else {
                $top.fadeOut(200);
            }
        });

        // Animate the scroll to top
        $top.click(function(event) {
            event.preventDefault();
            $('html, body').animate({scrollTop: 0}, 300);
        })

        // Makes sure that the href="#" attached to the <a> elements
        // don't scroll you back up the page.
        $('body').on('click', 'a[href="#"]', function(event) {
            event.preventDefault();
        });
    </script><script language=JavaScript type=text/javascript>
    /* From http://evirtus.net/pub/eflickrstream.asp */
    /* Global variables */
    var bolOnLoadRun=false;
    var bolFlickrRun=false;
    var objFlickrOutput=null;
    
    /* OnLoad events */
    window.onload = function() {
    bolOnLoadRun=true;
    if (! /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent) ) {
	eFlickrStream();
    };
    }
    
    /*
    eFlickrStream - Lovely, lovely photos! :-)
    - 02.08.2007 @ 14:33: Initial version
    */
    function eFlickrStream() {
    if (!bolFlickrRun ) { return false; } else { bolFlickrRun=false; }
    if ((!document.createElement) && (!document.getElementById) && (!document.getElementsByTagName) ) { return false; }// Test for required browser capabilities
    
    /*   *** Options/start ***   */
    var strTarget='flickrstream';// Target container for the flickr badge (must allready exist in the document)
    /*   *** Options/end ***     */
    
    if (!document.getElementById(strTarget)){return false;}// Exsist if target doesn't exsist
    
    var objTarget=document.getElementById(strTarget);
    objTarget.appendChild(objFlickrOutput);// Append output
    
    objFlickrOutput=null;// We're done, delete stored variable value
    objFlickr=null;
    }
    
    /*
    jsonFlickrFeed - Triggered when the Flickr json "feed" is loaded, generates Flickr photos output list item (Deefer "trigger method" from Patrick Quinn-Graham's DOM Flickr Badge)
    - 02.08.2007 @ 14:33: Initial version
    - 23.11.2007 @ 08:24: Updated to use eSetAttr(), enables the flickr link in IE
    - 29.11.2007 @ 05:52: Some changes for easier configuration (of both options and text-strings)
    */
    function jsonFlickrFeed(objFlickr) {
    if ((!document.createElement) && (!document.getElementById) && (!document.getElementsByTagName) ) { return false; }// Test for required browser capabilities
    
    /*   *** Options/start ***   */
    var intMaxImages=10;// Maximum number of images to show (1-20)
    var bolThumbSquare=true;// Load the square thumbnails
    var intThumbWidth=75;// Thumbnail width (omitted if set to "0")
    var strLightbox='flickrstream';// Lightbox "group name" (define to mark the thumbnails for lightbox usage, adds rel="lightbox[value]" to image links)
    var strImgAlt='[title]';// Alternative title for images ("[title]" will be replaced by image title)
    var strImgLinkTitle='View a larger version of \"[title]\"';// Link title for the image link
    /*   *** Options/end ***     */
    
    var objElm,objTxt,objImg,objLnk,objTmp,strTmp;
    var intPhotos=objFlickr.items.length;
    var objOut=document.createElement('ul');
    objOut.setAttribute('class','flickrlist');
    
    for (var iCntA=0; ( (iCntA<intPhotos) && (iCntA<intMaxImages)); iCntA++) {
    
	objElm=document.createElement('li');// Create item container element (<li>)
    
	objLnk=document.createElement('a');// Create link (to the large(r) photo)
	objLnk.setAttribute('href',objFlickr.items[iCntA].link);
	objLnk.setAttribute('title',strImgLinkTitle.replace('[title]',objFlickr.items[iCntA].title));
	if (strLightbox!=''){objLnk.setAttribute('rel','lightbox['+strLightbox+']');}// Add relation value for lightbox usage
    
	strTmp=objFlickr.items[iCntA].media.m;// Retreive thumbnail URI
	if (bolThumbSquare){strTmp=strTmp.replace('_m.jpg','_s.jpg');}// Swap default thumbnail for square...
    
	objImg=document.createElement('img');// Main thumbnail
	eSetAttr(objImg,'class','photo');
	objImg.setAttribute('src',strTmp);
	objImg.setAttribute('alt',strImgAlt.replace('[title]',objFlickr.items[iCntA].title));
	if (intThumbWidth!=0){objImg.setAttribute('width',intThumbWidth);}
    
	objLnk.appendChild(objImg);// Append thumbnail to link
	objElm.appendChild(objLnk);// Append link to container (li)

	objOut.appendChild(objElm);// Append container to output object
	}
    
    objFlickrOutput=objOut;// Store output for later use...
    
    if (bolOnLoadRun) {
	eFlickrStream();
	}
    else {
	bolFlickrRun=true;
	}
    }
    
    /*
    eSetAttr/eGetAttr - An attempt to tame IE's weird DOM model
    - 22.11.2007 @ 12:50 - Initial version
    */
    function eSetAttr(objTarget,strAttr,strValue) {
    if (typeof window.attachEvent!='undefined' && typeof window.opera=='undefined') {
    //    //Set attributes for IE
	switch (strAttr) {
	    case('class'):
		objTarget.setAttribute('className',strValue);
		break;
	    case('style'):
		objTarget.style.cssText=strValue;
		break;
	    default:
		objTarget.setAttribute(strAttr,strValue);
		break;
	    }
	}
    else {
    //    //Set attributes for /Other browsers/
	objTarget.setAttribute(strAttr,strValue);
	}
    //66885349@N03
    }
    </script><script type=text/javascript src="https://api.flickr.com/services/feeds/photos_public.gne?id=66885349@N03&format=json&amp;" defer=defer></script><script src=https://apis.google.com/js/platform.js async defer></script><script type=text/javascript>
        var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
        document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
    </script><script type=text/javascript>
        try {
            var pageTracker = _gat._getTracker("UA-55589822-1");
            pageTracker._trackPageview();
            } catch(err) {}
    </script></body></html>